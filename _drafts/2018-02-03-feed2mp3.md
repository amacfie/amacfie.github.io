---
layout: post
title: "Converting an RSS feed to podcast with Python"
---

What if there's a blog we like...  and we never have time to read it...
but we would have time to listen to it as a podcast!?
This tiny Python script will let us do just that.

First, we'll need some packages...

    pip3 install goose3
    pip3 install unidecode
    pip3 install beautifulsoup4
    pip3 install feedparser
    pip3 install gtts

... and import statements.

    from bs4 import BeautifulSoup
    from goose3 import Goose
    from gtts import gTTS
    import feedparser
    import html
    import re
    import unidecode

We'll need some reusable code to generate a filename for each blog post.
The filename can be based on the post title, and maybe the date in front so the
files easily stay in order, but the title might contain weird characters.
So the function `slugify` takes any text and returns a filename-friendly
version.

    def slugify(value):
        # convert to ASCII
        value = unidecode.unidecode(value)
        # make lowercase
        value = re.sub('[^\w\s-]', '', value).strip().lower()
        # whitespace -> hyphen
        value = re.sub('[-\s]+', '-', value)
        return value

[Goose](https://github.com/grangier/python-goose) is a Python library for
extracting articles from web pages.
That means Goose takes a webpage and removes everything except for the
actual text of the main content of the page;
no navigation, no ads, no junk.

    g = Goose({'parser_class': 'soup'})

[Feedparser](http://pythonhosted.org/feedparser/) is a Python library for...
parsing feeds.
RSS and Atom formats are supported and the API is the same either way.
We'll load the feed URL from an active blog,
<http://www.overcomingbias.com>.

    d = feedparser.parse('http://www.overcomingbias.com/feed')

With the feed parsed and Goose ready to go, we'll loop through the
entries (blog posts) in the feed and save an mp3 file for each one.

    for entry in d.entries:
        # get date field (y m d)
        entry_date = ' '.join(str(x) for x in entry.published_parsed[0:3])
        # get title field
        entry_title = entry.title
        print('  Converting "' + entry_title + '"...')
        # create slugified filename
        entry_name = slugify(entry_date + '_' + entry_title)
        filename = entry_name + '.mp3'
        # if the feed contains the content, use that; otherwise use the URL
        if 'content' in entry:
            content_text = g.extract(
                raw_html=entry.content[0]['value']).cleaned_text
        else:
            content_text = g.extract(url=entry['link']).cleaned_text
        # use Google text-to-speech to convert from text to mp3 file
        print('  Saving to ' + filename + '...')
        tts = gTTS(text=content_text, lang='en')
        tts.save(filename)

We're done!

